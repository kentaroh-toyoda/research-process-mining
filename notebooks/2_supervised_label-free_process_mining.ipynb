{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8b94b13-6e05-4935-8b1e-a9ff8d73ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import random \n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e158b1da-5e32-446b-8df6-6e6210880889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_event_log(dataset_path=None, n_rows=1000):\n",
    "    print('Reading', dataset_path)\n",
    "    try:\n",
    "        event_log = pd.read_csv(dataset_path, nrows=n_rows)\n",
    "    except:\n",
    "        return None\n",
    "    h = event_log.columns.values.tolist()\n",
    "    # check if a dataset contains a tuple of case_id, activity, and timestamp\n",
    "    if ('case:concept:name' in h) and ('concept:name' in h) and ('time:timestamp' in h):\n",
    "        # pre-process an event log\n",
    "        return event_log.fillna(np.nan).replace([np.nan], [''])\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "372b98f5-3097-4b5c-937e-d6129d7ce2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extraction: \n",
    "# input: expect a vector of values in a column\n",
    "# output: set of features\n",
    "def local_feature_extraction(value, round_digits=3):\n",
    "    patterns = ['[a-z]', '[A-Z]', '\\d', '\\s', '[^a-zA-Z\\d\\s]']\n",
    "    f = {}\n",
    "    if len(value) == 0:\n",
    "        f['f_chars'] = 0 \n",
    "        f['f_words'] = 0\n",
    "        for p in patterns:\n",
    "            f['f_{}'.format(p)] = 0\n",
    "    else:\n",
    "        # length: length of a value\n",
    "        f['f_chars'] = len(value)\n",
    "        # words: number of words in a value\n",
    "        f['f_words'] = len(re.findall(r'\\w+', value))\n",
    "        # The following code find the frequency of each pattern in patterns in a value\n",
    "        for p in patterns:\n",
    "            f['f_{}'.format(p)] = round(len(re.findall(p, value)) / len(value), round_digits)\n",
    "    return f\n",
    "\n",
    "def feature_extraction(values, round_digits=3):\n",
    "    # set type of values string\n",
    "    values = values.astype(str)\n",
    "    # local features\n",
    "    f_local = [local_feature_extraction(value) for value in values]\n",
    "    # convert it into a DF to easily calculate mean of each feature\n",
    "    f = pd.DataFrame.from_dict(f_local)\n",
    "    f = f.apply(np.mean, axis=0)\n",
    "    # global features\n",
    "    # count the occurence of each value in values\n",
    "    counts = Counter(values).values()\n",
    "    if len(counts) > 1:\n",
    "        # find the mean and variance of counts\n",
    "        # append global features\n",
    "        f['f_ratio_unique_values'] = round(len(set(values)) / len(values), round_digits)\n",
    "        f['f_mean_unique_values'] = round(statistics.mean(counts), round_digits)\n",
    "    else:\n",
    "        f['f_ratio_unique_values'] = 1\n",
    "        f['f_mean_unique_values'] = 1\n",
    "    return f.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a218ed1d-8b6b-48eb-a264-c287a7fda592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../datasets/BPIC2015_2.csv\n",
      "Reading ../datasets/BPIC2013_incident_management.csv\n",
      "Reading ../datasets/BPIC2018.csv\n",
      "Reading ../datasets/BPIC2013_problem_management_open_problems.csv\n",
      "Reading ../datasets/BPIC2016_Clicks_NOT_Logged_In.csv\n",
      "Reading ../datasets/BPIC2015_5.csv\n",
      "Reading ../datasets/BPIC2015_4.csv\n",
      "Reading ../datasets/BPIC2016_Clicks_Logged_In.csv\n",
      "Reading ../datasets/BPIC2014_change_log.csv\n",
      "Reading ../datasets/Production_Data.csv\n",
      "Reading ../datasets/BPIC2011_Dutch_academic_hospital.csv\n",
      "Reading ../datasets/BPIC2017.csv\n",
      "Reading ../datasets/BPIC2013_problem_management_closed_problems.csv\n",
      "Reading ../datasets/BPIC2015_3.csv\n",
      "Reading ../datasets/BPIC2012_loan_application_process.csv\n",
      "Reading ../datasets/BPIC2019_purchase_order_handling_process.csv\n",
      "Reading ../datasets/BPI2016_Clicks_Logged_In.csv\n",
      "Reading ../datasets/BPIC2015_1.csv\n",
      "Reading ../datasets/BPI2016_Clicks_NOT_Logged_In.csv\n",
      "Datasets found in the dataset dir: 19\n",
      "Datasets that are ready for evaluation: 13\n"
     ]
    }
   ],
   "source": [
    "datasets = glob.glob('../datasets/*.csv', recursive=False)\n",
    "event_logs = [load_event_log(d, n_rows=1000) for d in datasets]\n",
    "# remove None from event_logs\n",
    "event_logs = [e for e in event_logs if e is not None]\n",
    "print('Datasets found in the dataset dir:', len(datasets))\n",
    "print('Datasets that are ready for evaluation:', len(event_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297a7d30-9cc0-47b5-9ac2-599b6407ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [e.apply(lambda x: feature_extraction(x), axis=0) for e in event_logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c1f9deb-af94-4879-8bc2-790831fb2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relabel: if a label is a key label, keep it. Otherwise, relabel it as 'other'\n",
    "def relabel(labels):\n",
    "    return np.array([label if re.search(r'case:concept:name|concept:name|time:timestamp', label) else 'other' \\\n",
    "                     for label in labels])\n",
    "\n",
    "# flatten: flatten an array of arrays\n",
    "# https://stackoverflow.com/a/952952/7184459\n",
    "def flatten(x):\n",
    "    return [x_elem_elem for x_elem in x for x_elem_elem in x_elem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59f5fa12-bd8b-4712-a19a-dc2872086e48",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.67      0.29      0.40         7\n",
      "     concept:name       0.67      0.29      0.40         7\n",
      "            other       0.95      0.99      0.97       278\n",
      "   time:timestamp       1.00      0.43      0.60         7\n",
      "\n",
      "         accuracy                           0.95       299\n",
      "        macro avg       0.82      0.50      0.59       299\n",
      "     weighted avg       0.94      0.95      0.94       299\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       1.00      0.17      0.29         6\n",
      "     concept:name       0.50      0.17      0.25         6\n",
      "            other       0.92      0.97      0.94       112\n",
      "   time:timestamp       0.75      1.00      0.86         6\n",
      "\n",
      "         accuracy                           0.90       130\n",
      "        macro avg       0.79      0.58      0.58       130\n",
      "     weighted avg       0.89      0.90      0.88       130\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.80      0.57      0.67         7\n",
      "     concept:name       0.50      0.14      0.22         7\n",
      "            other       0.95      0.99      0.97       223\n",
      "   time:timestamp       1.00      0.71      0.83         7\n",
      "\n",
      "         accuracy                           0.95       244\n",
      "        macro avg       0.81      0.60      0.67       244\n",
      "     weighted avg       0.94      0.95      0.94       244\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.83      0.83      0.83         6\n",
      "     concept:name       0.50      0.17      0.25         6\n",
      "            other       0.96      0.98      0.97       167\n",
      "   time:timestamp       0.75      1.00      0.86         6\n",
      "\n",
      "         accuracy                           0.95       185\n",
      "        macro avg       0.76      0.74      0.73       185\n",
      "     weighted avg       0.94      0.95      0.94       185\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       1.00      0.14      0.25         7\n",
      "     concept:name       0.00      0.00      0.00         7\n",
      "            other       0.91      0.90      0.90       142\n",
      "   time:timestamp       0.44      1.00      0.61         7\n",
      "\n",
      "         accuracy                           0.83       163\n",
      "        macro avg       0.59      0.51      0.44       163\n",
      "     weighted avg       0.85      0.83      0.82       163\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.60      0.50      0.55         6\n",
      "     concept:name       1.00      0.17      0.29         6\n",
      "            other       0.97      0.99      0.98       248\n",
      "   time:timestamp       1.00      1.00      1.00         6\n",
      "\n",
      "         accuracy                           0.96       266\n",
      "        macro avg       0.89      0.66      0.70       266\n",
      "     weighted avg       0.96      0.96      0.96       266\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       1.00      0.29      0.44         7\n",
      "     concept:name       0.00      0.00      0.00         7\n",
      "            other       0.90      0.98      0.94       115\n",
      "   time:timestamp       0.78      1.00      0.88         7\n",
      "\n",
      "         accuracy                           0.90       136\n",
      "        macro avg       0.67      0.57      0.57       136\n",
      "     weighted avg       0.86      0.90      0.86       136\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.67      0.67      0.67         6\n",
      "     concept:name       1.00      0.33      0.50         6\n",
      "            other       0.97      0.99      0.98       275\n",
      "   time:timestamp       1.00      0.83      0.91         6\n",
      "\n",
      "         accuracy                           0.97       293\n",
      "        macro avg       0.91      0.71      0.76       293\n",
      "     weighted avg       0.97      0.97      0.97       293\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.50      0.14      0.22         7\n",
      "     concept:name       0.00      0.00      0.00         7\n",
      "            other       0.95      0.99      0.97       270\n",
      "   time:timestamp       0.78      1.00      0.88         7\n",
      "\n",
      "         accuracy                           0.95       291\n",
      "        macro avg       0.56      0.53      0.52       291\n",
      "     weighted avg       0.92      0.95      0.93       291\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.75      0.50      0.60         6\n",
      "     concept:name       0.50      0.17      0.25         6\n",
      "            other       0.92      0.98      0.95       120\n",
      "   time:timestamp       1.00      0.67      0.80         6\n",
      "\n",
      "         accuracy                           0.91       138\n",
      "        macro avg       0.79      0.58      0.65       138\n",
      "     weighted avg       0.90      0.91      0.90       138\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.67      0.29      0.40         7\n",
      "     concept:name       0.00      0.00      0.00         7\n",
      "            other       0.91      0.87      0.89       146\n",
      "   time:timestamp       0.47      1.00      0.64         7\n",
      "\n",
      "         accuracy                           0.81       167\n",
      "        macro avg       0.51      0.54      0.48       167\n",
      "     weighted avg       0.85      0.81      0.82       167\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.50      0.33      0.40         6\n",
      "     concept:name       0.00      0.00      0.00         6\n",
      "            other       0.96      0.99      0.97       244\n",
      "   time:timestamp       1.00      0.83      0.91         6\n",
      "\n",
      "         accuracy                           0.95       262\n",
      "        macro avg       0.61      0.54      0.57       262\n",
      "     weighted avg       0.92      0.95      0.93       262\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.80      0.57      0.67         7\n",
      "     concept:name       1.00      0.14      0.25         7\n",
      "            other       0.97      1.00      0.98       282\n",
      "   time:timestamp       1.00      0.86      0.92         7\n",
      "\n",
      "         accuracy                           0.96       303\n",
      "        macro avg       0.94      0.64      0.71       303\n",
      "     weighted avg       0.96      0.96      0.96       303\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.83      0.83      0.83         6\n",
      "     concept:name       0.00      0.00      0.00         6\n",
      "            other       0.94      0.96      0.95       108\n",
      "   time:timestamp       0.67      1.00      0.80         6\n",
      "\n",
      "         accuracy                           0.91       126\n",
      "        macro avg       0.61      0.70      0.65       126\n",
      "     weighted avg       0.87      0.91      0.89       126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.67      0.29      0.40         7\n",
      "     concept:name       0.50      0.43      0.46         7\n",
      "            other       0.95      0.96      0.95       176\n",
      "   time:timestamp       0.70      1.00      0.82         7\n",
      "\n",
      "         accuracy                           0.92       197\n",
      "        macro avg       0.70      0.67      0.66       197\n",
      "     weighted avg       0.91      0.92      0.91       197\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.67      0.33      0.44         6\n",
      "     concept:name       0.00      0.00      0.00         6\n",
      "            other       0.95      0.99      0.97       214\n",
      "   time:timestamp       1.00      0.67      0.80         6\n",
      "\n",
      "         accuracy                           0.94       232\n",
      "        macro avg       0.65      0.50      0.55       232\n",
      "     weighted avg       0.92      0.94      0.93       232\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.80      0.57      0.67         7\n",
      "     concept:name       0.67      0.29      0.40         7\n",
      "            other       0.97      0.99      0.98       245\n",
      "   time:timestamp       0.88      1.00      0.93         7\n",
      "\n",
      "         accuracy                           0.96       266\n",
      "        macro avg       0.83      0.71      0.74       266\n",
      "     weighted avg       0.95      0.96      0.95       266\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.80      0.67      0.73         6\n",
      "     concept:name       0.00      0.00      0.00         6\n",
      "            other       0.95      0.98      0.96       145\n",
      "   time:timestamp       0.75      1.00      0.86         6\n",
      "\n",
      "         accuracy                           0.93       163\n",
      "        macro avg       0.62      0.66      0.64       163\n",
      "     weighted avg       0.90      0.93      0.91       163\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       0.67      0.57      0.62         7\n",
      "     concept:name       0.67      0.29      0.40         7\n",
      "            other       0.97      0.99      0.98       291\n",
      "   time:timestamp       1.00      0.71      0.83         7\n",
      "\n",
      "         accuracy                           0.96       312\n",
      "        macro avg       0.82      0.64      0.71       312\n",
      "     weighted avg       0.95      0.96      0.95       312\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "case:concept:name       1.00      0.33      0.50         6\n",
      "     concept:name       0.00      0.00      0.00         6\n",
      "            other       0.91      0.97      0.94        99\n",
      "   time:timestamp       0.67      1.00      0.80         6\n",
      "\n",
      "         accuracy                           0.89       117\n",
      "        macro avg       0.64      0.58      0.56       117\n",
      "     weighted avg       0.85      0.89      0.86       117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "n_splits = 2\n",
    "n_repeats = 10\n",
    "n_estimators = 100\n",
    "\n",
    "# extract labels and features\n",
    "y = np.array([np.array(relabel(e.columns.values)) for e in tmp], dtype=object)\n",
    "X = np.array([np.transpose(e).values for e in tmp], dtype=object)\n",
    "# performance evaluation using CV\n",
    "rkf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "for train_index, test_index in rkf.split(range(len(X))):\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    X_train, X_test = flatten(X[train_index]), flatten(X[test_index])\n",
    "    y_train, y_test = flatten(y[train_index]), flatten(y[test_index])\n",
    "    clf.fit(X_train, y_train)\n",
    "    # evaluate the classifier\n",
    "    y_predicted = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
