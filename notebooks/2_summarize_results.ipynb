{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b0d8f-dd93-4901-865d-3e24bd6323ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(font='monospace', style='whitegrid', font_scale=1.5)\n",
    "# plt.rcParams['font.family'] = 'monospace'\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "# plt.rcParams['font.sans-serif'] = ['Liberation Sans']\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f0f12-bf4f-4d93-810d-edc5ebd71346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "[f.name for f in fm.fontManager.ttflist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dad9ef-6194-4c7e-916e-88167a89bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette('Paired')\n",
    "colors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f580e-1983-4658-adbf-6d342a1160be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'../results/results.pickle', 'rb') as result_file:\n",
    "    results = pickle.load(result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5e48f-9f31-47ff-a851-e661d3f688e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# covert from dict to DF\n",
    "r = pd.DataFrame.from_dict(results)\n",
    "# only handle the BPIC datasets\n",
    "r = r.loc[r.dataset.str.contains('BPIC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f825f6-018e-48f9-9170-c4c8e8d4f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output dataset information for papers\n",
    "datasets = {}\n",
    "dataset_names = [re.match('../datasets/(.+).csv', x).groups()[0] for x in list(sorted(set(r['dataset'])))]\n",
    "# datasets['Dataset'] = [re.sub('_', ' ', x) for x in dataset_names]\n",
    "datasets['dataset'] = dataset_names\n",
    "\n",
    "datasets['Number of Columns'] = [len(pd.read_csv(x, nrows=1).columns) for x in list(sorted(set(r['dataset'])))]\n",
    "r['dataset'] = r['dataset'].apply(lambda x: re.match('../datasets/(.+).csv', x).groups()[0])\n",
    "\n",
    "print(pd.DataFrame.from_dict(datasets).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32507e67-60b8-4b9d-acae-2c2eee511f32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if the correct tuple is included in the candidates\n",
    "r['is_in'] = r[['correct_indices', 'cands']].apply(lambda x: x['correct_indices'] in x['cands'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d679633-7a2d-40b1-a502-8c00395228cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if the candidate with the highest score is the correct one\n",
    "def if_highest_cands_is_correct(x):\n",
    "    if x['n_cands'] == 0:\n",
    "        # this means that no candidate is identified. return a dummy tuple\n",
    "        return [[-1, -1, -1]]\n",
    "    elif x['n_cands'] == 1:\n",
    "        # this means that we only have a single candidate at the first stage\n",
    "        return [np.array(x['cands']).flatten().tolist()]\n",
    "    else:\n",
    "        return [x['cands'][i] for i in np.argwhere(np.amax(x['scores']) == x['scores']).flatten().tolist()]\n",
    "    \n",
    "r['identified_indices'] = r.apply(lambda x: if_highest_cands_is_correct(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36250e29-a2ef-4207-a416-d164cedafc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find identification accuracy by each key column\n",
    "r['case_id_precision'] = r.apply(lambda x: sum([i[0] == x['correct_indices'][0] for i in x['identified_indices']]) / len(x['identified_indices']), axis=1)\n",
    "r['timestamp_precision'] = r.apply(lambda x: sum([i[1] == x['correct_indices'][1] for i in x['identified_indices']]) / len(x['identified_indices']), axis=1)\n",
    "r['activity_precision'] = r.apply(lambda x: sum([i[2] == x['correct_indices'][2] for i in x['identified_indices']]) / len(x['identified_indices']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9d75ae-e50c-40da-b7f3-b21a408f66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all columns are correctly identified\n",
    "r['is_all_correct'] = r.apply(lambda x: x['correct_indices'] in x['identified_indices'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab950dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'../results/results_first_stage.pickle', 'rb') as result_file:\n",
    "    results_first_stage = pickle.load(result_file)\n",
    "tmp = pd.DataFrame.from_dict(results_first_stage)\n",
    "\n",
    "# Filter out no candidate cases\n",
    "tmp = tmp[tmp['n_cands'] > 0]\n",
    "\n",
    "# Checking if candidates exist in correct_indices\n",
    "tmp['is_kept_in_first_stage_case_id'] = tmp.apply(lambda x: x['correct_indices'][0] in [i[0] for i in x[['cands']][0]], axis=1)\n",
    "tmp['is_kept_in_first_stage_timestamp'] = tmp.apply(lambda x: x['correct_indices'][1] in [i[1] for i in x[['cands']][0]], axis=1)\n",
    "tmp['is_kept_in_first_stage_activity'] = tmp.apply(lambda x: x['correct_indices'][2] in [i[2] for i in x[['cands']][0]], axis=1)\n",
    "\n",
    "result_tmp_case_id = tmp.groupby(['dataset', 'n_top_cands'])\\\n",
    "      .apply(lambda x: sum(x['is_kept_in_first_stage_case_id']) / len(x['is_kept_in_first_stage_case_id']))\\\n",
    "      .groupby(['n_top_cands'])\\\n",
    "      .apply(lambda x: round(np.mean(x), ndigits=2))\\\n",
    "      .reset_index(name='value')\n",
    "result_tmp_case_id['attribute'] = 'case-id'     \n",
    "\n",
    "result_tmp_timestamp = tmp.groupby(['dataset', 'n_top_cands'])\\\n",
    "      .apply(lambda x: sum(x['is_kept_in_first_stage_timestamp']) / len(x['is_kept_in_first_stage_timestamp']))\\\n",
    "      .groupby(['n_top_cands'])\\\n",
    "      .apply(lambda x: round(np.mean(x), ndigits=2))\\\n",
    "      .reset_index(name='value')\n",
    "result_tmp_timestamp['attribute'] = 'timestamp'\n",
    "\n",
    "result_tmp_activity = tmp.groupby(['dataset', 'n_top_cands'])\\\n",
    "      .apply(lambda x: sum(x['is_kept_in_first_stage_activity']) / len(x['is_kept_in_first_stage_activity']))\\\n",
    "      .groupby(['n_top_cands'])\\\n",
    "      .apply(lambda x: round(np.mean(x), ndigits=2))\\\n",
    "      .reset_index(name='value')\n",
    "result_tmp_activity['attribute'] = 'activity'\n",
    "\n",
    "tmp = pd.concat([result_tmp_case_id, result_tmp_timestamp, result_tmp_activity])\n",
    "display(tmp)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale=1.5)\n",
    "sns.lineplot(data=tmp, x='n_top_cands', y='value', hue='attribute',\n",
    "            palette=sns.color_palette('deep', n_colors=3), linewidth=3)\n",
    "plt.legend(title='Attribute', loc='lower right')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Coverage')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.savefig('../plots/coverage_k.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5768f520-9065-41a1-89ab-a7e32555f7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find how much we could identify all the key columns correctly\n",
    "# conditions:\n",
    "r.groupby(['dataset', 'n_top_cands']).apply(lambda x: round(sum(x['is_all_correct']) / len(x), ndigits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5326dcc-8038-42bd-8980-a33f5c7b3a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = pd.merge(\n",
    "    r.groupby(['dataset']).apply(lambda x: round(sum(x['case_id_precision']) / len(x), ndigits=2)).reset_index(name='case_id'),\n",
    "    r.groupby(['dataset']).apply(lambda x: round(sum(x['activity_precision']) / len(x), ndigits=2)).reset_index(name='activity'), \n",
    "    on='dataset')\n",
    "pd.merge(\n",
    "    tmp,\n",
    "    r.groupby(['dataset']).apply(lambda x: round(sum(x['timestamp_precision']) / len(x), ndigits=2)).reset_index(name='timestamp'),\n",
    "    on='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ddd0d-1d00-40f2-a68e-78bc1facfb01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r_time = r.groupby(['n_top_cands', 'metric'])\\\n",
    "    .apply(lambda x: round(np.mean(x['time_cand_selection'] + x['time_score_eval']), ndigits=2))\\\n",
    "    .to_frame('time')\\\n",
    "    .reset_index()\n",
    "display(r_time)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.set_style('darkgrid')\n",
    "# sns.set(font_scale=1.5)\n",
    "sns.barplot(data=r_time, hue='n_top_cands', y='time', x='metric',\n",
    "            order=['simplicity', 'fitness', 'generalization', 'precision', 'Buijs2014'],\n",
    "            palette=sns.color_palette('Paired'))\n",
    "plt.legend(title='k', fontsize=20)\n",
    "plt.xlabel('Metric', fontsize=20)\n",
    "plt.xticks(fontsize=11)\n",
    "plt.ylabel('Computation time [s]', fontsize=20)\n",
    "plt.savefig('../plots/computation_time.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa36d24-d128-45f2-8686-4fe58aa16692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def precision_summary(x):\n",
    "    c = round(sum(x['case_id_precision']) / len(x), ndigits=2)\n",
    "    t = round(sum(x['timestamp_precision']) / len(x), ndigits=2)\n",
    "    a = round(sum(x['activity_precision']) / len(x), ndigits=2)\n",
    "    avg = round(np.mean([c, t, a]), ndigits=2)\n",
    "    return pd.DataFrame({'accuracy': [c, t, a, avg]}, \n",
    "                        index=['case-id', 'timestamp', 'activity', 'average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac704adb-5617-490b-9bdd-62245f0873f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# metric (accuracy and time)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# tmp = r.loc[(r['miner'] == 'inductive_miner') & (len(r['scores']) > 0)]\\\n",
    "tmp = r.groupby(['metric', 'n_top_cands'])\\\n",
    ".apply(func=precision_summary)\\\n",
    ".reset_index()\n",
    "display(tmp)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale=1.5)\n",
    "sns.barplot(data=tmp, x='metric', y='accuracy', hue='n_top_cands',\n",
    "            order=['simplicity', 'fitness', 'generalization', 'precision', 'Buijs2014'],\n",
    "            palette=sns.color_palette('Paired'))\n",
    "plt.legend(title='k', fontsize=14)\n",
    "plt.xlabel('Metric', fontsize=20)\n",
    "plt.xticks(fontsize=11)\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "plt.savefig('../plots/accuracy_metric.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3cf308-b4c2-4721-985d-1ce8fc4b7e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = r.groupby(['n_top_cands'])\\\n",
    "    .apply(precision_summary)\\\n",
    "    .reset_index()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale=1.5)\n",
    "sns.barplot(data=tmp, x='level_1', y='accuracy', hue='n_top_cands',\n",
    "            order=['case-id', 'timestamp', 'activity'],\n",
    "            palette=sns.color_palette('Paired'))\n",
    "plt.legend(title='k')\n",
    "plt.xlabel('Attribute')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 0.8)\n",
    "plt.savefig('../plots/accuracy_by_attribute.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b34fb8-b8ac-4a7b-a171-e13929987721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# metric (accuracy and miner)\n",
    "# conditions: \n",
    "\n",
    "tmp = r.groupby(['miner'])\\\n",
    "    .apply(func=precision_summary)\\\n",
    "    .reset_index()\n",
    "display(tmp)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale=1.5)\n",
    "sns.barplot(data=tmp, x='level_1', y='accuracy', hue='miner',\n",
    "            order=['case-id', 'timestamp', 'activity'],\n",
    "            palette=sns.color_palette('Paired'))\n",
    "plt.legend(title='Miner', loc='lower right')\n",
    "plt.xlabel('Attribute')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 0.7)\n",
    "plt.savefig('../plots/accuracy_miner.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2223f9-4579-4106-9f1f-274ad904d0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# miner (accuracy and time?)\n",
    "tmp = r[['dataset', 'miner', 'n_top_cands', 'case_id_precision', 'activity_precision', 'timestamp_precision']]\n",
    "# replace miner == None with 'NA' when no miner was used (i.e., only identified at stage 1)\n",
    "tmp.fillna('NA', inplace=True)\n",
    "tmp.groupby(['dataset', 'miner', 'n_top_cands']) \\\n",
    ".apply(lambda x: round(np.mean(x), ndigits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e81dd-0ce0-42d9-a641-d7ced843b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy vs number of columns \n",
    "tmp = r.groupby(['dataset'])\\\n",
    ".apply(func=precision_summary)\\\n",
    ".reset_index()\n",
    "tmp = tmp.loc[tmp['level_1'] == 'average']\n",
    "tmp2 = pd.DataFrame.from_dict(datasets)\n",
    "\n",
    "r_acc_n_col = pd.merge(tmp, tmp2, on='dataset', how='outer')\n",
    "display(r_acc_n_col)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale=1.5)\n",
    "sns.scatterplot(data=r_acc_n_col, x='Number of Columns', y='accuracy', s=100)\n",
    "plt.xlabel('Number of Attributes')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig('../plots/accuracy_n_columns.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9142e-234f-4127-acd5-12321051865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = r.groupby(['n_top_cands', 'miner'])\\\n",
    "    .apply(lambda x: round(np.mean(x['time_cand_selection']), ndigits=2))\\\n",
    "    .to_frame('time')\\\n",
    "    .reset_index()\n",
    "display(tmp)\n",
    "\n",
    "tmp = r.groupby(['n_top_cands', 'miner'])\\\n",
    "    .apply(lambda x: round(np.mean(x['time_score_eval']), ndigits=2))\\\n",
    "    .to_frame('time')\\\n",
    "    .reset_index()\n",
    "display(tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
